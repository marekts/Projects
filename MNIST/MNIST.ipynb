{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D\n",
    "from keras.applications import VGG16\n",
    "from keras.utils import np_utils\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (42000, 785), test shape: (28000, 784)\n"
     ]
    }
   ],
   "source": [
    "train_data = pd.read_csv('train.csv')\n",
    "test_data = pd.read_csv('test.csv')\n",
    "\n",
    "print('Train shape: {0}, test shape: {1}'.format(train_data.shape, test_data.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels, data = train_data['label'].values, train_data.iloc[:, 1:].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(42000, 784)\n",
      "0 255\n"
     ]
    }
   ],
   "source": [
    "print(data.shape)\n",
    "print(np.min(data), np.max(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x576 with 5 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Check a few digits\n",
    "\n",
    "sample_digits = np.random.randint(0, len(data), 5)\n",
    "\n",
    "fig = plt.figure(figsize=(15, 8))\n",
    "plt.subplots_adjust(0.)\n",
    "i = 1\n",
    "for x in sample_digits:\n",
    "    ax = fig.add_subplot(1, 5, i)\n",
    "    i += 1\n",
    "    ax.set_title('True value: {0}'.format(labels[x]))\n",
    "    digit = data[x].reshape(28, 28)\n",
    "    plt.imshow(digit, cmap = plt.cm.binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale train and test data from 1 to 0\n",
    "test = test_data.values\n",
    "\n",
    "if np.max(data) > 1: data = data / 255\n",
    "if np.max(test) > 1: test = test / 255\n",
    "    \n",
    "# Convert labels to categorical\n",
    "y = np_utils.to_categorical(labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data, y, test_size=0.2, random_state=46)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build  MLP models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_inputs = X_train.shape[1]\n",
    "num_outputs = y.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_10 (Dense)             (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 10)                2570      \n",
      "=================================================================\n",
      "Total params: 535,818\n",
      "Trainable params: 535,818\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# MLP model 2 hidden layers\n",
    "first_mlp_model = Sequential([\n",
    "    Dense(512, input_dim=num_inputs, activation='relu'),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dense(num_outputs, activation='softmax')\n",
    "])\n",
    "\n",
    "first_mlp_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "first_mlp_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 33600 samples, validate on 8400 samples\n",
      "Epoch 1/12\n",
      " - 4s - loss: 0.0158 - accuracy: 0.9947 - val_loss: 0.1095 - val_accuracy: 0.9755\n",
      "Epoch 2/12\n",
      " - 4s - loss: 0.0066 - accuracy: 0.9980 - val_loss: 0.1039 - val_accuracy: 0.9764\n",
      "Epoch 3/12\n",
      " - 4s - loss: 0.0016 - accuracy: 0.9997 - val_loss: 0.1027 - val_accuracy: 0.9793\n",
      "Epoch 4/12\n",
      " - 4s - loss: 0.0022 - accuracy: 0.9994 - val_loss: 0.1065 - val_accuracy: 0.9782\n",
      "Epoch 5/12\n",
      " - 5s - loss: 0.0016 - accuracy: 0.9996 - val_loss: 0.0984 - val_accuracy: 0.9808\n",
      "Epoch 6/12\n",
      " - 5s - loss: 3.1465e-04 - accuracy: 1.0000 - val_loss: 0.1011 - val_accuracy: 0.9811\n",
      "Epoch 7/12\n",
      " - 5s - loss: 1.5549e-04 - accuracy: 1.0000 - val_loss: 0.1021 - val_accuracy: 0.9810\n",
      "Epoch 8/12\n",
      " - 5s - loss: 1.2341e-04 - accuracy: 1.0000 - val_loss: 0.1040 - val_accuracy: 0.9811\n",
      "Epoch 9/12\n",
      " - 5s - loss: 1.0491e-04 - accuracy: 1.0000 - val_loss: 0.1060 - val_accuracy: 0.9808\n",
      "Epoch 10/12\n",
      " - 5s - loss: 9.2128e-05 - accuracy: 1.0000 - val_loss: 0.1071 - val_accuracy: 0.9808\n",
      "Epoch 11/12\n",
      " - 5s - loss: 8.1379e-05 - accuracy: 1.0000 - val_loss: 0.1082 - val_accuracy: 0.9811\n",
      "Epoch 12/12\n",
      " - 5s - loss: 7.3365e-05 - accuracy: 1.0000 - val_loss: 0.1090 - val_accuracy: 0.9807\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1a94798150>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_mlp_model.fit(X_train, y_train,\n",
    "         batch_size=256,\n",
    "         epochs=12,\n",
    "         verbose=2,\n",
    "         validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MLP model 3 hidden layers and dropouts\n",
    "second_mlp_model = Sequential([\n",
    "    Dense(1024, input_dim=num_inputs, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    \n",
    "    Dense(512, activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    \n",
    "    Dense(256, activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    \n",
    "    Dense(num_outputs, activation='softmax')\n",
    "])\n",
    "\n",
    "second_mlp_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 33600 samples, validate on 8400 samples\n",
      "Epoch 1/12\n",
      " - 23s - loss: 0.4522 - accuracy: 0.8607 - val_loss: 0.1551 - val_accuracy: 0.9533\n",
      "Epoch 2/12\n",
      " - 15s - loss: 0.1743 - accuracy: 0.9460 - val_loss: 0.1116 - val_accuracy: 0.9664\n",
      "Epoch 3/12\n",
      " - 15s - loss: 0.1268 - accuracy: 0.9603 - val_loss: 0.0937 - val_accuracy: 0.9714\n",
      "Epoch 4/12\n",
      " - 15s - loss: 0.1044 - accuracy: 0.9676 - val_loss: 0.0816 - val_accuracy: 0.9758\n",
      "Epoch 5/12\n",
      " - 15s - loss: 0.0871 - accuracy: 0.9719 - val_loss: 0.0831 - val_accuracy: 0.9750\n",
      "Epoch 6/12\n",
      " - 14s - loss: 0.0745 - accuracy: 0.9754 - val_loss: 0.0823 - val_accuracy: 0.9771\n",
      "Epoch 7/12\n",
      " - 14s - loss: 0.0676 - accuracy: 0.9783 - val_loss: 0.0796 - val_accuracy: 0.9771\n",
      "Epoch 8/12\n",
      " - 14s - loss: 0.0583 - accuracy: 0.9806 - val_loss: 0.0791 - val_accuracy: 0.9769\n",
      "Epoch 9/12\n",
      " - 14s - loss: 0.0578 - accuracy: 0.9815 - val_loss: 0.0835 - val_accuracy: 0.9783\n",
      "Epoch 10/12\n",
      " - 14s - loss: 0.0497 - accuracy: 0.9835 - val_loss: 0.0777 - val_accuracy: 0.9798\n",
      "Epoch 11/12\n",
      " - 14s - loss: 0.0477 - accuracy: 0.9836 - val_loss: 0.0826 - val_accuracy: 0.9794\n",
      "Epoch 12/12\n",
      " - 14s - loss: 0.0428 - accuracy: 0.9858 - val_loss: 0.0749 - val_accuracy: 0.9811\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1a9c48ab10>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "second_mlp_model.fit(X_train, y_train,\n",
    "         batch_size=256,\n",
    "         epochs=12,\n",
    "         verbose=2,\n",
    "         validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8400/8400 [==============================] - 2s 235us/step\n",
      "Loss: 0.07485243178066975, Accuracy: 0.981071412563324\n"
     ]
    }
   ],
   "source": [
    "score = second_mlp_model.evaluate(X_test, y_test)\n",
    "print('Loss: {0}, Accuracy: {1}'.format(score[0], score[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build CNN models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resize X and y for CNN\n",
    "X_train_resized = X_train.reshape(X_train.shape[0], 28, 28, 1)\n",
    "X_test_resized = X_test.reshape(X_test.shape[0], 28, 28, 1)\n",
    "\n",
    "input_shape = X_train_resized.shape[1:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test shape: (33600, 28, 28, 1), train shape: (8400, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "print('Test shape: {0}, train shape: {1}'.format(X_train_resized.shape, X_test_resized.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_58\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_146 (Conv2D)          (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_97 (MaxPooling (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_177 (Dropout)        (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_147 (Conv2D)          (None, 11, 11, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_98 (MaxPooling (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_178 (Dropout)        (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_44 (Flatten)         (None, 1600)              0         \n",
      "_________________________________________________________________\n",
      "dense_156 (Dense)            (None, 512)               819712    \n",
      "_________________________________________________________________\n",
      "dropout_179 (Dropout)        (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_157 (Dense)            (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 843,658\n",
      "Trainable params: 843,658\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 33600 samples, validate on 8400 samples\n",
      "Epoch 1/15\n",
      " - 56s - loss: 0.4464 - accuracy: 0.8594 - val_loss: 0.1119 - val_accuracy: 0.9680\n",
      "Epoch 2/15\n",
      " - 55s - loss: 0.1260 - accuracy: 0.9613 - val_loss: 0.0717 - val_accuracy: 0.9792\n",
      "Epoch 3/15\n",
      " - 52s - loss: 0.0885 - accuracy: 0.9720 - val_loss: 0.0516 - val_accuracy: 0.9839\n",
      "Epoch 4/15\n",
      " - 48s - loss: 0.0679 - accuracy: 0.9790 - val_loss: 0.0467 - val_accuracy: 0.9864\n",
      "Epoch 5/15\n",
      " - 48s - loss: 0.0569 - accuracy: 0.9821 - val_loss: 0.0393 - val_accuracy: 0.9886\n",
      "Epoch 6/15\n",
      " - 48s - loss: 0.0505 - accuracy: 0.9836 - val_loss: 0.0393 - val_accuracy: 0.9880\n",
      "Epoch 7/15\n",
      " - 49s - loss: 0.0450 - accuracy: 0.9853 - val_loss: 0.0395 - val_accuracy: 0.9882\n",
      "Epoch 8/15\n",
      " - 50s - loss: 0.0395 - accuracy: 0.9871 - val_loss: 0.0351 - val_accuracy: 0.9910\n",
      "Epoch 9/15\n",
      " - 51s - loss: 0.0318 - accuracy: 0.9896 - val_loss: 0.0338 - val_accuracy: 0.9900\n",
      "Epoch 10/15\n",
      " - 50s - loss: 0.0312 - accuracy: 0.9899 - val_loss: 0.0329 - val_accuracy: 0.9900\n",
      "Epoch 11/15\n",
      " - 50s - loss: 0.0307 - accuracy: 0.9898 - val_loss: 0.0334 - val_accuracy: 0.9900\n",
      "Epoch 12/15\n",
      " - 49s - loss: 0.0260 - accuracy: 0.9911 - val_loss: 0.0328 - val_accuracy: 0.9907\n",
      "Epoch 13/15\n",
      " - 50s - loss: 0.0253 - accuracy: 0.9915 - val_loss: 0.0300 - val_accuracy: 0.9899\n",
      "Epoch 14/15\n",
      " - 48s - loss: 0.0240 - accuracy: 0.9923 - val_loss: 0.0302 - val_accuracy: 0.9918\n",
      "Epoch 15/15\n",
      " - 52s - loss: 0.0218 - accuracy: 0.9926 - val_loss: 0.0329 - val_accuracy: 0.9907\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1b5e5e9090>"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Two conv layers\n",
    "simple_cnn = Sequential([\n",
    "    Conv2D(32, kernel_size=(3,3), input_shape=input_shape, activation='relu'),\n",
    "    MaxPool2D(pool_size=(2,2)),\n",
    "    Dropout(0.3),\n",
    "    \n",
    "    Conv2D(64, kernel_size=(3,3), activation='relu'),\n",
    "    MaxPool2D(pool_size=(2,2)),\n",
    "    Dropout(0.3),\n",
    "    \n",
    "    Flatten(),\n",
    "    \n",
    "    Dense(512, activation='relu'),\n",
    "    Dropout(0.3),\n",
    "    \n",
    "    Dense(num_outputs, activation='softmax')\n",
    "])\n",
    "\n",
    "simple_cnn.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "simple_cnn.summary()\n",
    "\n",
    "simple_cnn.fit(X_train_resized, y_train,\n",
    "              batch_size=256,\n",
    "              epochs=15,\n",
    "              verbose=2,\n",
    "              validation_data=(X_test_resized, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_63\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_160 (Conv2D)          (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_111 (MaxPoolin (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_199 (Dropout)        (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_161 (Conv2D)          (None, 11, 11, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_112 (MaxPoolin (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_200 (Dropout)        (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_162 (Conv2D)          (None, 3, 3, 128)         73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_113 (MaxPoolin (None, 1, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_201 (Dropout)        (None, 1, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_49 (Flatten)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_169 (Dense)            (None, 1024)              132096    \n",
      "_________________________________________________________________\n",
      "dropout_202 (Dropout)        (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_170 (Dense)            (None, 10)                10250     \n",
      "=================================================================\n",
      "Total params: 235,018\n",
      "Trainable params: 235,018\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 33600 samples, validate on 8400 samples\n",
      "Epoch 1/15\n",
      " - 54s - loss: 0.8534 - accuracy: 0.7185 - val_loss: 0.1961 - val_accuracy: 0.9396\n",
      "Epoch 2/15\n",
      " - 53s - loss: 0.2571 - accuracy: 0.9217 - val_loss: 0.1220 - val_accuracy: 0.9611\n",
      "Epoch 3/15\n",
      " - 50s - loss: 0.1819 - accuracy: 0.9444 - val_loss: 0.0926 - val_accuracy: 0.9719\n",
      "Epoch 4/15\n",
      " - 50s - loss: 0.1500 - accuracy: 0.9535 - val_loss: 0.0791 - val_accuracy: 0.9740\n",
      "Epoch 5/15\n",
      " - 51s - loss: 0.1313 - accuracy: 0.9598 - val_loss: 0.0697 - val_accuracy: 0.9768\n",
      "Epoch 6/15\n",
      " - 52s - loss: 0.1118 - accuracy: 0.9646 - val_loss: 0.0629 - val_accuracy: 0.9794\n",
      "Epoch 7/15\n",
      " - 51s - loss: 0.1023 - accuracy: 0.9683 - val_loss: 0.0598 - val_accuracy: 0.9806\n",
      "Epoch 8/15\n",
      " - 51s - loss: 0.0989 - accuracy: 0.9690 - val_loss: 0.0563 - val_accuracy: 0.9823\n",
      "Epoch 9/15\n",
      " - 50s - loss: 0.0889 - accuracy: 0.9724 - val_loss: 0.0511 - val_accuracy: 0.9846\n",
      "Epoch 10/15\n",
      " - 50s - loss: 0.0816 - accuracy: 0.9737 - val_loss: 0.0517 - val_accuracy: 0.9837\n",
      "Epoch 11/15\n",
      " - 54s - loss: 0.0791 - accuracy: 0.9760 - val_loss: 0.0462 - val_accuracy: 0.9858\n",
      "Epoch 12/15\n",
      " - 53s - loss: 0.0720 - accuracy: 0.9778 - val_loss: 0.0442 - val_accuracy: 0.9864\n",
      "Epoch 13/15\n",
      " - 51s - loss: 0.0711 - accuracy: 0.9776 - val_loss: 0.0470 - val_accuracy: 0.9858\n",
      "Epoch 14/15\n",
      " - 51s - loss: 0.0680 - accuracy: 0.9783 - val_loss: 0.0486 - val_accuracy: 0.9849\n",
      "Epoch 15/15\n",
      " - 52s - loss: 0.0676 - accuracy: 0.9775 - val_loss: 0.0460 - val_accuracy: 0.9868\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1b6e423b10>"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Three conv layers\n",
    "three_conv = Sequential([\n",
    "    Conv2D(32, kernel_size=(3,3), input_shape=input_shape, activation='relu'),\n",
    "    MaxPool2D(pool_size=(2,2)),\n",
    "    Dropout(0.3),\n",
    "    \n",
    "    Conv2D(64, kernel_size=(3,3), activation='relu'),\n",
    "    MaxPool2D(pool_size=(2,2)),\n",
    "    Dropout(0.3),\n",
    "    \n",
    "    Conv2D(128, kernel_size=(3,3), activation='relu'),\n",
    "    MaxPool2D(pool_size=(2,2)),\n",
    "    Dropout(0.3),\n",
    "    \n",
    "    Flatten(),\n",
    "    \n",
    "    Dense(1024, activation='relu'),\n",
    "    Dropout(0.3),\n",
    "    \n",
    "    Dense(num_outputs, activation='softmax')\n",
    "])\n",
    "\n",
    "three_conv.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "three_conv.summary()\n",
    "\n",
    "three_conv.fit(X_train_resized, y_train,\n",
    "              batch_size=256,\n",
    "              epochs=15,\n",
    "              verbose=2,\n",
    "              validation_data=(X_test_resized, y_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_83\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_243 (Conv2D)          (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "conv2d_244 (Conv2D)          (None, 24, 24, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_150 (MaxPoolin (None, 12, 12, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_264 (Dropout)        (None, 12, 12, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_245 (Conv2D)          (None, 12, 12, 64)        18496     \n",
      "_________________________________________________________________\n",
      "conv2d_246 (Conv2D)          (None, 10, 10, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_151 (MaxPoolin (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_265 (Dropout)        (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_69 (Flatten)         (None, 1600)              0         \n",
      "_________________________________________________________________\n",
      "dense_215 (Dense)            (None, 1024)              1639424   \n",
      "_________________________________________________________________\n",
      "dropout_266 (Dropout)        (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_216 (Dense)            (None, 10)                10250     \n",
      "=================================================================\n",
      "Total params: 1,714,666\n",
      "Trainable params: 1,714,666\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 33600 samples, validate on 8400 samples\n",
      "Epoch 1/20\n",
      " - 107s - loss: 0.4115 - accuracy: 0.8674 - val_loss: 0.0844 - val_accuracy: 0.9739\n",
      "Epoch 2/20\n",
      " - 87s - loss: 0.0902 - accuracy: 0.9711 - val_loss: 0.0475 - val_accuracy: 0.9862\n",
      "Epoch 3/20\n",
      " - 94s - loss: 0.0641 - accuracy: 0.9796 - val_loss: 0.0419 - val_accuracy: 0.9879\n",
      "Epoch 4/20\n",
      " - 85s - loss: 0.0532 - accuracy: 0.9830 - val_loss: 0.0345 - val_accuracy: 0.9895\n",
      "Epoch 5/20\n",
      " - 90s - loss: 0.0439 - accuracy: 0.9864 - val_loss: 0.0352 - val_accuracy: 0.9885\n",
      "Epoch 6/20\n",
      " - 86s - loss: 0.0371 - accuracy: 0.9880 - val_loss: 0.0297 - val_accuracy: 0.9913\n",
      "Epoch 7/20\n",
      " - 86s - loss: 0.0329 - accuracy: 0.9895 - val_loss: 0.0300 - val_accuracy: 0.9905\n",
      "Epoch 8/20\n",
      " - 85s - loss: 0.0300 - accuracy: 0.9912 - val_loss: 0.0283 - val_accuracy: 0.9920\n",
      "Epoch 9/20\n",
      " - 87s - loss: 0.0268 - accuracy: 0.9917 - val_loss: 0.0278 - val_accuracy: 0.9924\n",
      "Epoch 10/20\n",
      " - 85s - loss: 0.0224 - accuracy: 0.9924 - val_loss: 0.0321 - val_accuracy: 0.9919\n",
      "Epoch 11/20\n",
      " - 87s - loss: 0.0221 - accuracy: 0.9928 - val_loss: 0.0316 - val_accuracy: 0.9915\n",
      "Epoch 12/20\n",
      " - 86s - loss: 0.0205 - accuracy: 0.9932 - val_loss: 0.0316 - val_accuracy: 0.9908\n",
      "Epoch 13/20\n",
      " - 123s - loss: 0.0180 - accuracy: 0.9940 - val_loss: 0.0363 - val_accuracy: 0.9901\n",
      "Epoch 14/20\n",
      " - 129s - loss: 0.0174 - accuracy: 0.9937 - val_loss: 0.0369 - val_accuracy: 0.9911\n",
      "Epoch 15/20\n",
      " - 100s - loss: 0.0175 - accuracy: 0.9943 - val_loss: 0.0314 - val_accuracy: 0.9914\n",
      "Epoch 16/20\n",
      " - 101s - loss: 0.0159 - accuracy: 0.9948 - val_loss: 0.0284 - val_accuracy: 0.9918\n",
      "Epoch 17/20\n",
      " - 92s - loss: 0.0128 - accuracy: 0.9955 - val_loss: 0.0347 - val_accuracy: 0.9911\n",
      "Epoch 18/20\n",
      " - 90s - loss: 0.0148 - accuracy: 0.9948 - val_loss: 0.0295 - val_accuracy: 0.9926\n",
      "Epoch 19/20\n",
      " - 85s - loss: 0.0125 - accuracy: 0.9957 - val_loss: 0.0299 - val_accuracy: 0.9918\n",
      "Epoch 20/20\n",
      " - 87s - loss: 0.0141 - accuracy: 0.9954 - val_loss: 0.0284 - val_accuracy: 0.9937\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1ba2e7d850>"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Two double conv layers\n",
    "doubled_cnn = Sequential([\n",
    "    Conv2D(32, kernel_size=(3,3), input_shape=input_shape, activation='relu'),\n",
    "    Conv2D(32, kernel_size=(3,3), activation='relu'),\n",
    "    MaxPool2D(pool_size=(2,2)),\n",
    "    Dropout(0.5),\n",
    "    \n",
    "    Conv2D(64, kernel_size=(3,3), padding='same', activation='relu'),\n",
    "    Conv2D(64, kernel_size=(3,3), activation='relu'),\n",
    "    MaxPool2D(pool_size=(2,2)),\n",
    "    Dropout(0.3),\n",
    "    \n",
    "    Flatten(),\n",
    "    \n",
    "    Dense(1024, activation='relu'),\n",
    "    Dropout(0.3),\n",
    "    \n",
    "    Dense(num_outputs, activation='softmax')\n",
    "])\n",
    "\n",
    "doubled_cnn.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "doubled_cnn.summary()\n",
    "\n",
    "doubled_cnn.fit(X_train_resized, y_train,\n",
    "              batch_size=256,\n",
    "              epochs=20,\n",
    "              verbose=2,\n",
    "              validation_data=(X_test_resized, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_92\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_298 (Conv2D)          (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "conv2d_299 (Conv2D)          (None, 24, 24, 32)        9248      \n",
      "_________________________________________________________________\n",
      "conv2d_300 (Conv2D)          (None, 22, 22, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_169 (MaxPoolin (None, 11, 11, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_293 (Dropout)        (None, 11, 11, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_301 (Conv2D)          (None, 11, 11, 64)        18496     \n",
      "_________________________________________________________________\n",
      "conv2d_302 (Conv2D)          (None, 9, 9, 64)          36928     \n",
      "_________________________________________________________________\n",
      "conv2d_303 (Conv2D)          (None, 7, 7, 64)          36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_170 (MaxPoolin (None, 3, 3, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_294 (Dropout)        (None, 3, 3, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_78 (Flatten)         (None, 576)               0         \n",
      "_________________________________________________________________\n",
      "dense_234 (Dense)            (None, 1024)              590848    \n",
      "_________________________________________________________________\n",
      "dropout_295 (Dropout)        (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_235 (Dense)            (None, 10)                10250     \n",
      "=================================================================\n",
      "Total params: 712,266\n",
      "Trainable params: 712,266\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 33600 samples, validate on 8400 samples\n",
      "Epoch 1/15\n",
      " - 99s - loss: 0.6898 - accuracy: 0.7711 - val_loss: 0.1394 - val_accuracy: 0.9565\n",
      "Epoch 2/15\n",
      " - 91s - loss: 0.1527 - accuracy: 0.9526 - val_loss: 0.0783 - val_accuracy: 0.9761\n",
      "Epoch 3/15\n",
      " - 92s - loss: 0.0963 - accuracy: 0.9704 - val_loss: 0.0550 - val_accuracy: 0.9835\n",
      "Epoch 4/15\n",
      " - 90s - loss: 0.0754 - accuracy: 0.9769 - val_loss: 0.0454 - val_accuracy: 0.9869\n",
      "Epoch 5/15\n",
      " - 90s - loss: 0.0682 - accuracy: 0.9786 - val_loss: 0.0475 - val_accuracy: 0.9856\n",
      "Epoch 6/15\n",
      " - 90s - loss: 0.0568 - accuracy: 0.9815 - val_loss: 0.0401 - val_accuracy: 0.9875\n",
      "Epoch 7/15\n",
      " - 90s - loss: 0.0485 - accuracy: 0.9845 - val_loss: 0.0364 - val_accuracy: 0.9887\n",
      "Epoch 8/15\n",
      " - 91s - loss: 0.0425 - accuracy: 0.9860 - val_loss: 0.0320 - val_accuracy: 0.9906\n",
      "Epoch 9/15\n",
      " - 90s - loss: 0.0387 - accuracy: 0.9875 - val_loss: 0.0328 - val_accuracy: 0.9906\n",
      "Epoch 10/15\n",
      " - 90s - loss: 0.0333 - accuracy: 0.9890 - val_loss: 0.0347 - val_accuracy: 0.9896\n",
      "Epoch 11/15\n",
      " - 91s - loss: 0.0337 - accuracy: 0.9892 - val_loss: 0.0295 - val_accuracy: 0.9906\n",
      "Epoch 12/15\n",
      " - 91s - loss: 0.0305 - accuracy: 0.9899 - val_loss: 0.0306 - val_accuracy: 0.9910\n",
      "Epoch 13/15\n",
      " - 91s - loss: 0.0276 - accuracy: 0.9909 - val_loss: 0.0290 - val_accuracy: 0.9912\n",
      "Epoch 14/15\n",
      " - 94s - loss: 0.0268 - accuracy: 0.9910 - val_loss: 0.0278 - val_accuracy: 0.9919\n",
      "Epoch 15/15\n",
      " - 91s - loss: 0.0297 - accuracy: 0.9900 - val_loss: 0.0287 - val_accuracy: 0.9919\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1bb5430e50>"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Two triple conv layers\n",
    "triple_cnn = Sequential([\n",
    "    \n",
    "    Conv2D(32, kernel_size=(3,3), input_shape=input_shape, activation='relu'),\n",
    "    Conv2D(32, kernel_size=(3,3), activation='relu'),\n",
    "    Conv2D(32, kernel_size=(3,3), activation='relu'),\n",
    "    MaxPool2D(pool_size=(2,2)),\n",
    "    Dropout(0.5),\n",
    "    \n",
    "    Conv2D(64, kernel_size=(3,3), padding='same', activation='relu'),\n",
    "    Conv2D(64, kernel_size=(3,3), activation='relu'),\n",
    "    Conv2D(64, kernel_size=(3,3), activation='relu'),\n",
    "    MaxPool2D(pool_size=(2,2)),\n",
    "    Dropout(0.3),\n",
    "    \n",
    "    Flatten(),\n",
    "    \n",
    "    Dense(1024, activation='relu'),\n",
    "    Dropout(0.3),\n",
    "    \n",
    "    Dense(num_outputs, activation='softmax')\n",
    "])\n",
    "\n",
    "triple_cnn.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "triple_cnn.summary()\n",
    "\n",
    "triple_cnn.fit(X_train_resized, y_train,\n",
    "              batch_size=512,\n",
    "              epochs=15,\n",
    "              verbose=2,\n",
    "              validation_data=(X_test_resized, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8400/8400 [==============================] - 9s 1ms/step\n",
      "Loss: 0.028446206388842776, Accuracy: 0.9936904907226562\n"
     ]
    }
   ],
   "source": [
    "cnn_score = doubled_cnn.evaluate(X_test_resized, y_test)\n",
    "print('Loss: {0}, Accuracy: {1}'.format(cnn_score[0], cnn_score[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction on test part and save results in csv\n",
    "test = test.reshape(test.shape[0], 28, 28, 1)\n",
    "y_pred = doubled_cnn.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_id = np.arange(1, test.shape[0]+1)\n",
    "\n",
    "prediction = []\n",
    "for i in range(len(label_id)):\n",
    "    prediction.append(np.argmax(y_pred[i]))\n",
    "    \n",
    "submission = pd.DataFrame({'ImageId': label_id, 'Label': prediction})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('predict_digits.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
