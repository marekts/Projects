{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D\n",
    "from keras.utils import np_utils\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (42000, 785), test shape: (28000, 784)\n"
     ]
    }
   ],
   "source": [
    "train_data = pd.read_csv('train.csv')\n",
    "test_data = pd.read_csv('test.csv')\n",
    "\n",
    "print('Train shape: {0}, test shape: {1}'.format(train_data.shape, test_data.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels, data = train_data['label'].values, train_data.iloc[:, 1:].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(42000, 784)\n",
      "0 255\n"
     ]
    }
   ],
   "source": [
    "print(data.shape)\n",
    "print(np.min(data), np.max(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x576 with 5 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Check a few digits\n",
    "\n",
    "sample_digits = np.random.randint(0, len(data), 5)\n",
    "\n",
    "fig = plt.figure(figsize=(15, 8))\n",
    "plt.subplots_adjust(0.)\n",
    "i = 1\n",
    "for x in sample_digits:\n",
    "    ax = fig.add_subplot(1, 5, i)\n",
    "    i += 1\n",
    "    ax.set_title('True value: {0}'.format(labels[x]))\n",
    "    digit = data[x].reshape(28, 28)\n",
    "    plt.imshow(digit, cmap = plt.cm.binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale train and test data from 1 to 0\n",
    "test = test_data.values\n",
    "\n",
    "if np.max(data) > 1: data = data / 255\n",
    "if np.max(test) > 1: test = test / 255\n",
    "    \n",
    "# Convert labels to categorical\n",
    "y = np_utils.to_categorical(labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data, y, test_size=0.2, random_state=46)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build  MLP models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_inputs = X_train.shape[1]\n",
    "num_outputs = y.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_10 (Dense)             (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 10)                2570      \n",
      "=================================================================\n",
      "Total params: 535,818\n",
      "Trainable params: 535,818\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# MLP model 2 hidden layers\n",
    "first_mlp_model = Sequential([\n",
    "    Dense(512, input_dim=num_inputs, activation='relu'),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dense(num_outputs, activation='softmax')\n",
    "])\n",
    "\n",
    "first_mlp_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "first_mlp_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 33600 samples, validate on 8400 samples\n",
      "Epoch 1/12\n",
      " - 4s - loss: 0.0158 - accuracy: 0.9947 - val_loss: 0.1095 - val_accuracy: 0.9755\n",
      "Epoch 2/12\n",
      " - 4s - loss: 0.0066 - accuracy: 0.9980 - val_loss: 0.1039 - val_accuracy: 0.9764\n",
      "Epoch 3/12\n",
      " - 4s - loss: 0.0016 - accuracy: 0.9997 - val_loss: 0.1027 - val_accuracy: 0.9793\n",
      "Epoch 4/12\n",
      " - 4s - loss: 0.0022 - accuracy: 0.9994 - val_loss: 0.1065 - val_accuracy: 0.9782\n",
      "Epoch 5/12\n",
      " - 5s - loss: 0.0016 - accuracy: 0.9996 - val_loss: 0.0984 - val_accuracy: 0.9808\n",
      "Epoch 6/12\n",
      " - 5s - loss: 3.1465e-04 - accuracy: 1.0000 - val_loss: 0.1011 - val_accuracy: 0.9811\n",
      "Epoch 7/12\n",
      " - 5s - loss: 1.5549e-04 - accuracy: 1.0000 - val_loss: 0.1021 - val_accuracy: 0.9810\n",
      "Epoch 8/12\n",
      " - 5s - loss: 1.2341e-04 - accuracy: 1.0000 - val_loss: 0.1040 - val_accuracy: 0.9811\n",
      "Epoch 9/12\n",
      " - 5s - loss: 1.0491e-04 - accuracy: 1.0000 - val_loss: 0.1060 - val_accuracy: 0.9808\n",
      "Epoch 10/12\n",
      " - 5s - loss: 9.2128e-05 - accuracy: 1.0000 - val_loss: 0.1071 - val_accuracy: 0.9808\n",
      "Epoch 11/12\n",
      " - 5s - loss: 8.1379e-05 - accuracy: 1.0000 - val_loss: 0.1082 - val_accuracy: 0.9811\n",
      "Epoch 12/12\n",
      " - 5s - loss: 7.3365e-05 - accuracy: 1.0000 - val_loss: 0.1090 - val_accuracy: 0.9807\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1a94798150>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_mlp_model.fit(X_train, y_train,\n",
    "         batch_size=256,\n",
    "         epochs=12,\n",
    "         verbose=2,\n",
    "         validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MLP model 3 hidden layers and dropouts\n",
    "second_mlp_model = Sequential([\n",
    "    Dense(1024, input_dim=num_inputs, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    \n",
    "    Dense(512, activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    \n",
    "    Dense(256, activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    \n",
    "    Dense(num_outputs, activation='softmax')\n",
    "])\n",
    "\n",
    "second_mlp_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 33600 samples, validate on 8400 samples\n",
      "Epoch 1/12\n",
      " - 23s - loss: 0.4522 - accuracy: 0.8607 - val_loss: 0.1551 - val_accuracy: 0.9533\n",
      "Epoch 2/12\n",
      " - 15s - loss: 0.1743 - accuracy: 0.9460 - val_loss: 0.1116 - val_accuracy: 0.9664\n",
      "Epoch 3/12\n",
      " - 15s - loss: 0.1268 - accuracy: 0.9603 - val_loss: 0.0937 - val_accuracy: 0.9714\n",
      "Epoch 4/12\n",
      " - 15s - loss: 0.1044 - accuracy: 0.9676 - val_loss: 0.0816 - val_accuracy: 0.9758\n",
      "Epoch 5/12\n",
      " - 15s - loss: 0.0871 - accuracy: 0.9719 - val_loss: 0.0831 - val_accuracy: 0.9750\n",
      "Epoch 6/12\n",
      " - 14s - loss: 0.0745 - accuracy: 0.9754 - val_loss: 0.0823 - val_accuracy: 0.9771\n",
      "Epoch 7/12\n",
      " - 14s - loss: 0.0676 - accuracy: 0.9783 - val_loss: 0.0796 - val_accuracy: 0.9771\n",
      "Epoch 8/12\n",
      " - 14s - loss: 0.0583 - accuracy: 0.9806 - val_loss: 0.0791 - val_accuracy: 0.9769\n",
      "Epoch 9/12\n",
      " - 14s - loss: 0.0578 - accuracy: 0.9815 - val_loss: 0.0835 - val_accuracy: 0.9783\n",
      "Epoch 10/12\n",
      " - 14s - loss: 0.0497 - accuracy: 0.9835 - val_loss: 0.0777 - val_accuracy: 0.9798\n",
      "Epoch 11/12\n",
      " - 14s - loss: 0.0477 - accuracy: 0.9836 - val_loss: 0.0826 - val_accuracy: 0.9794\n",
      "Epoch 12/12\n",
      " - 14s - loss: 0.0428 - accuracy: 0.9858 - val_loss: 0.0749 - val_accuracy: 0.9811\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1a9c48ab10>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "second_mlp_model.fit(X_train, y_train,\n",
    "         batch_size=256,\n",
    "         epochs=12,\n",
    "         verbose=2,\n",
    "         validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8400/8400 [==============================] - 2s 235us/step\n",
      "Loss: 0.07485243178066975, Accuracy: 0.981071412563324\n"
     ]
    }
   ],
   "source": [
    "score = second_mlp_model.evaluate(X_test, y_test)\n",
    "print('Loss: {0}, Accuracy: {1}'.format(score[0], score[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build CNN models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resize X and y for CNN\n",
    "X_train_resized = X_train.reshape(X_train.shape[0], 28, 28, 1)\n",
    "X_test_resized = X_test.reshape(X_test.shape[0], 28, 28, 1)\n",
    "\n",
    "input_shape = X_train_resized.shape[1:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test shape: (33600, 28, 28, 1), train shape: (8400, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "print('Test shape: {0}, train shape: {1}'.format(X_train_resized.shape, X_test_resized.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_5 (Conv2D)            (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 11, 11, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 1600)              0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 512)               819712    \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 843,658\n",
      "Trainable params: 843,658\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Two conv layers\n",
    "simple_cnn = Sequential([\n",
    "    Conv2D(32, kernel_size=(3,3), input_shape=input_shape, activation='relu'),\n",
    "    MaxPool2D(pool_size=(2,2)),\n",
    "    Dropout(0.3),\n",
    "    \n",
    "    Conv2D(64, kernel_size=(3,3), activation='relu'),\n",
    "    MaxPool2D(pool_size=(2,2)),\n",
    "    Dropout(0.3),\n",
    "    \n",
    "    Flatten(),\n",
    "    \n",
    "    Dense(512, activation='relu'),\n",
    "    Dropout(0.3),\n",
    "    \n",
    "    Dense(num_outputs, activation='softmax')\n",
    "])\n",
    "\n",
    "simple_cnn.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "simple_cnn.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 33600 samples, validate on 8400 samples\n",
      "Epoch 1/15\n",
      " - 70s - loss: 0.0081 - accuracy: 0.9975 - val_loss: 0.0258 - val_accuracy: 0.9940\n",
      "Epoch 2/15\n",
      " - 52s - loss: 0.0068 - accuracy: 0.9977 - val_loss: 0.0253 - val_accuracy: 0.9943\n",
      "Epoch 3/15\n",
      " - 55s - loss: 0.0059 - accuracy: 0.9978 - val_loss: 0.0264 - val_accuracy: 0.9938\n",
      "Epoch 4/15\n",
      " - 55s - loss: 0.0062 - accuracy: 0.9978 - val_loss: 0.0268 - val_accuracy: 0.9939\n",
      "Epoch 5/15\n",
      " - 55s - loss: 0.0057 - accuracy: 0.9981 - val_loss: 0.0288 - val_accuracy: 0.9942\n",
      "Epoch 6/15\n",
      " - 54s - loss: 0.0057 - accuracy: 0.9980 - val_loss: 0.0277 - val_accuracy: 0.9940\n",
      "Epoch 7/15\n",
      " - 54s - loss: 0.0054 - accuracy: 0.9980 - val_loss: 0.0271 - val_accuracy: 0.9937\n",
      "Epoch 8/15\n",
      " - 52s - loss: 0.0064 - accuracy: 0.9978 - val_loss: 0.0304 - val_accuracy: 0.9938\n",
      "Epoch 9/15\n",
      " - 55s - loss: 0.0058 - accuracy: 0.9979 - val_loss: 0.0325 - val_accuracy: 0.9935\n",
      "Epoch 10/15\n",
      " - 60s - loss: 0.0051 - accuracy: 0.9982 - val_loss: 0.0293 - val_accuracy: 0.9939\n",
      "Epoch 11/15\n",
      " - 55s - loss: 0.0061 - accuracy: 0.9979 - val_loss: 0.0279 - val_accuracy: 0.9931\n",
      "Epoch 12/15\n",
      " - 54s - loss: 0.0056 - accuracy: 0.9980 - val_loss: 0.0294 - val_accuracy: 0.9940\n",
      "Epoch 13/15\n",
      " - 53s - loss: 0.0055 - accuracy: 0.9980 - val_loss: 0.0327 - val_accuracy: 0.9940\n",
      "Epoch 14/15\n",
      " - 51s - loss: 0.0069 - accuracy: 0.9978 - val_loss: 0.0323 - val_accuracy: 0.9940\n",
      "Epoch 15/15\n",
      " - 51s - loss: 0.0052 - accuracy: 0.9982 - val_loss: 0.0329 - val_accuracy: 0.9935\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7fe4e5d97490>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple_cnn.fit(X_train_resized, y_train,\n",
    "              batch_size=256,\n",
    "              epochs=15,\n",
    "              verbose=2,\n",
    "              validation_data=(X_test_resized, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_21 (Conv2D)           (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_18 (Dropout)         (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_22 (Conv2D)           (None, 11, 11, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_12 (MaxPooling (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_19 (Dropout)         (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_23 (Conv2D)           (None, 3, 3, 128)         73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_13 (MaxPooling (None, 1, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_20 (Dropout)         (None, 1, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 1024)              132096    \n",
      "_________________________________________________________________\n",
      "dropout_21 (Dropout)         (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 10)                10250     \n",
      "=================================================================\n",
      "Total params: 235,018\n",
      "Trainable params: 235,018\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 33600 samples, validate on 8400 samples\n",
      "Epoch 1/15\n",
      " - 56s - loss: 0.8721 - accuracy: 0.7073 - val_loss: 0.2085 - val_accuracy: 0.9373\n",
      "Epoch 2/15\n",
      " - 52s - loss: 0.2681 - accuracy: 0.9172 - val_loss: 0.1221 - val_accuracy: 0.9640\n",
      "Epoch 3/15\n",
      " - 51s - loss: 0.1914 - accuracy: 0.9415 - val_loss: 0.1021 - val_accuracy: 0.9670\n",
      "Epoch 4/15\n",
      " - 52s - loss: 0.1592 - accuracy: 0.9509 - val_loss: 0.0807 - val_accuracy: 0.9755\n",
      "Epoch 5/15\n",
      " - 50s - loss: 0.1370 - accuracy: 0.9572 - val_loss: 0.0736 - val_accuracy: 0.9768\n",
      "Epoch 6/15\n",
      " - 51s - loss: 0.1193 - accuracy: 0.9626 - val_loss: 0.0668 - val_accuracy: 0.9785\n",
      "Epoch 7/15\n",
      " - 50s - loss: 0.1146 - accuracy: 0.9648 - val_loss: 0.0603 - val_accuracy: 0.9806\n",
      "Epoch 8/15\n",
      " - 51s - loss: 0.1025 - accuracy: 0.9678 - val_loss: 0.0639 - val_accuracy: 0.9808\n",
      "Epoch 9/15\n",
      " - 51s - loss: 0.0921 - accuracy: 0.9722 - val_loss: 0.0601 - val_accuracy: 0.9819\n",
      "Epoch 10/15\n",
      " - 51s - loss: 0.0864 - accuracy: 0.9733 - val_loss: 0.0507 - val_accuracy: 0.9852\n",
      "Epoch 11/15\n",
      " - 51s - loss: 0.0826 - accuracy: 0.9740 - val_loss: 0.0536 - val_accuracy: 0.9843\n",
      "Epoch 12/15\n",
      " - 51s - loss: 0.0784 - accuracy: 0.9764 - val_loss: 0.0504 - val_accuracy: 0.9843\n",
      "Epoch 13/15\n",
      " - 51s - loss: 0.0764 - accuracy: 0.9765 - val_loss: 0.0508 - val_accuracy: 0.9845\n",
      "Epoch 14/15\n",
      " - 51s - loss: 0.0743 - accuracy: 0.9770 - val_loss: 0.0468 - val_accuracy: 0.9861\n",
      "Epoch 15/15\n",
      " - 50s - loss: 0.0677 - accuracy: 0.9779 - val_loss: 0.0487 - val_accuracy: 0.9850\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7fe4eb9ba550>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Three conv layers\n",
    "three_conv = Sequential([\n",
    "    Conv2D(32, kernel_size=(3,3), input_shape=input_shape, activation='relu'),\n",
    "    MaxPool2D(pool_size=(2,2)),\n",
    "    Dropout(0.3),\n",
    "    \n",
    "    Conv2D(64, kernel_size=(3,3), activation='relu'),\n",
    "    MaxPool2D(pool_size=(2,2)),\n",
    "    Dropout(0.3),\n",
    "    \n",
    "    Conv2D(128, kernel_size=(3,3), activation='relu'),\n",
    "    MaxPool2D(pool_size=(2,2)),\n",
    "    Dropout(0.3),\n",
    "    \n",
    "    Flatten(),\n",
    "    \n",
    "    Dense(1024, activation='relu'),\n",
    "    Dropout(0.3),\n",
    "    \n",
    "    Dense(num_outputs, activation='softmax')\n",
    "])\n",
    "\n",
    "three_conv.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "three_conv.summary()\n",
    "\n",
    "three_conv.fit(X_train_resized, y_train,\n",
    "              batch_size=256,\n",
    "              epochs=15,\n",
    "              verbose=2,\n",
    "              validation_data=(X_test_resized, y_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_24 (Conv2D)           (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "conv2d_25 (Conv2D)           (None, 24, 24, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_14 (MaxPooling (None, 12, 12, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_22 (Dropout)         (None, 12, 12, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_26 (Conv2D)           (None, 12, 12, 64)        18496     \n",
      "_________________________________________________________________\n",
      "conv2d_27 (Conv2D)           (None, 10, 10, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_15 (MaxPooling (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_23 (Dropout)         (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_7 (Flatten)          (None, 1600)              0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 1024)              1639424   \n",
      "_________________________________________________________________\n",
      "dropout_24 (Dropout)         (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 10)                10250     \n",
      "=================================================================\n",
      "Total params: 1,714,666\n",
      "Trainable params: 1,714,666\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Two double conv layers\n",
    "doubled_cnn = Sequential([\n",
    "    Conv2D(32, kernel_size=(3,3), input_shape=input_shape, activation='relu'),\n",
    "    Conv2D(32, kernel_size=(3,3), activation='relu'),\n",
    "    MaxPool2D(pool_size=(2,2)),\n",
    "    Dropout(0.5),\n",
    "    \n",
    "    Conv2D(64, kernel_size=(3,3), padding='same', activation='relu'),\n",
    "    Conv2D(64, kernel_size=(3,3), activation='relu'),\n",
    "    MaxPool2D(pool_size=(2,2)),\n",
    "    Dropout(0.3),\n",
    "    \n",
    "    Flatten(),\n",
    "    \n",
    "    Dense(1024, activation='relu'),\n",
    "    Dropout(0.3),\n",
    "    \n",
    "    Dense(num_outputs, activation='softmax')\n",
    "])\n",
    "\n",
    "doubled_cnn.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "doubled_cnn.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 33600 samples, validate on 8400 samples\n",
      "Epoch 1/20\n",
      " - 91s - loss: 0.4221 - accuracy: 0.8636 - val_loss: 0.0872 - val_accuracy: 0.9724\n",
      "Epoch 2/20\n",
      " - 73s - loss: 0.0972 - accuracy: 0.9700 - val_loss: 0.0614 - val_accuracy: 0.9811\n",
      "Epoch 3/20\n",
      " - 72s - loss: 0.0653 - accuracy: 0.9797 - val_loss: 0.0449 - val_accuracy: 0.9869\n",
      "Epoch 4/20\n",
      " - 72s - loss: 0.0505 - accuracy: 0.9835 - val_loss: 0.0445 - val_accuracy: 0.9874\n",
      "Epoch 5/20\n",
      " - 73s - loss: 0.0440 - accuracy: 0.9858 - val_loss: 0.0437 - val_accuracy: 0.9860\n",
      "Epoch 6/20\n",
      " - 74s - loss: 0.0359 - accuracy: 0.9883 - val_loss: 0.0378 - val_accuracy: 0.9902\n",
      "Epoch 7/20\n",
      " - 72s - loss: 0.0316 - accuracy: 0.9898 - val_loss: 0.0386 - val_accuracy: 0.9885\n",
      "Epoch 8/20\n",
      " - 72s - loss: 0.0320 - accuracy: 0.9893 - val_loss: 0.0322 - val_accuracy: 0.9901\n",
      "Epoch 9/20\n",
      " - 72s - loss: 0.0260 - accuracy: 0.9920 - val_loss: 0.0296 - val_accuracy: 0.9907\n",
      "Epoch 10/20\n",
      " - 73s - loss: 0.0240 - accuracy: 0.9921 - val_loss: 0.0339 - val_accuracy: 0.9911\n",
      "Epoch 11/20\n",
      " - 72s - loss: 0.0257 - accuracy: 0.9918 - val_loss: 0.0307 - val_accuracy: 0.9913\n",
      "Epoch 12/20\n",
      " - 72s - loss: 0.0194 - accuracy: 0.9936 - val_loss: 0.0315 - val_accuracy: 0.9914\n",
      "Epoch 13/20\n",
      " - 73s - loss: 0.0210 - accuracy: 0.9934 - val_loss: 0.0303 - val_accuracy: 0.9927\n",
      "Epoch 14/20\n",
      " - 73s - loss: 0.0188 - accuracy: 0.9942 - val_loss: 0.0271 - val_accuracy: 0.9924\n",
      "Epoch 15/20\n",
      " - 105s - loss: 0.0181 - accuracy: 0.9944 - val_loss: 0.0270 - val_accuracy: 0.9915\n",
      "Epoch 16/20\n",
      " - 96s - loss: 0.0137 - accuracy: 0.9953 - val_loss: 0.0358 - val_accuracy: 0.9910\n",
      "Epoch 17/20\n",
      " - 92s - loss: 0.0157 - accuracy: 0.9954 - val_loss: 0.0317 - val_accuracy: 0.9905\n",
      "Epoch 18/20\n",
      " - 100s - loss: 0.0135 - accuracy: 0.9954 - val_loss: 0.0268 - val_accuracy: 0.9931\n",
      "Epoch 19/20\n",
      " - 102s - loss: 0.0139 - accuracy: 0.9952 - val_loss: 0.0334 - val_accuracy: 0.9912\n",
      "Epoch 20/20\n",
      " - 98s - loss: 0.0131 - accuracy: 0.9960 - val_loss: 0.0265 - val_accuracy: 0.9930\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7fe4ee8c1910>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doubled_cnn.fit(X_train_resized, y_train,\n",
    "              batch_size=256,\n",
    "              epochs=20,\n",
    "              verbose=2,\n",
    "              validation_data=(X_test_resized, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_28 (Conv2D)           (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "conv2d_29 (Conv2D)           (None, 24, 24, 32)        9248      \n",
      "_________________________________________________________________\n",
      "conv2d_30 (Conv2D)           (None, 22, 22, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_16 (MaxPooling (None, 11, 11, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_25 (Dropout)         (None, 11, 11, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_31 (Conv2D)           (None, 11, 11, 64)        18496     \n",
      "_________________________________________________________________\n",
      "conv2d_32 (Conv2D)           (None, 9, 9, 64)          36928     \n",
      "_________________________________________________________________\n",
      "conv2d_33 (Conv2D)           (None, 7, 7, 64)          36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_17 (MaxPooling (None, 3, 3, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_26 (Dropout)         (None, 3, 3, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_8 (Flatten)          (None, 576)               0         \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 1024)              590848    \n",
      "_________________________________________________________________\n",
      "dropout_27 (Dropout)         (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 10)                10250     \n",
      "=================================================================\n",
      "Total params: 712,266\n",
      "Trainable params: 712,266\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Two triple conv layers\n",
    "triple_cnn = Sequential([\n",
    "    \n",
    "    Conv2D(32, kernel_size=(3,3), input_shape=input_shape, activation='relu'),\n",
    "    Conv2D(32, kernel_size=(3,3), activation='relu'),\n",
    "    Conv2D(32, kernel_size=(3,3), activation='relu'),\n",
    "    MaxPool2D(pool_size=(2,2)),\n",
    "    Dropout(0.5),\n",
    "    \n",
    "    Conv2D(64, kernel_size=(3,3), padding='same', activation='relu'),\n",
    "    Conv2D(64, kernel_size=(3,3), activation='relu'),\n",
    "    Conv2D(64, kernel_size=(3,3), activation='relu'),\n",
    "    MaxPool2D(pool_size=(2,2)),\n",
    "    Dropout(0.3),\n",
    "    \n",
    "    Flatten(),\n",
    "    \n",
    "    Dense(1024, activation='relu'),\n",
    "    Dropout(0.3),\n",
    "    \n",
    "    Dense(num_outputs, activation='softmax')\n",
    "])\n",
    "\n",
    "triple_cnn.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "triple_cnn.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 33600 samples, validate on 8400 samples\n",
      "Epoch 1/15\n",
      " - 133s - loss: 0.4748 - accuracy: 0.8440 - val_loss: 0.1087 - val_accuracy: 0.9652\n",
      "Epoch 2/15\n",
      " - 104s - loss: 0.1127 - accuracy: 0.9650 - val_loss: 0.0521 - val_accuracy: 0.9837\n",
      "Epoch 3/15\n",
      " - 112s - loss: 0.0822 - accuracy: 0.9744 - val_loss: 0.0444 - val_accuracy: 0.9862\n",
      "Epoch 4/15\n",
      " - 102s - loss: 0.0601 - accuracy: 0.9813 - val_loss: 0.0385 - val_accuracy: 0.9875\n",
      "Epoch 5/15\n",
      " - 103s - loss: 0.0517 - accuracy: 0.9840 - val_loss: 0.0370 - val_accuracy: 0.9889\n",
      "Epoch 6/15\n",
      " - 103s - loss: 0.0465 - accuracy: 0.9855 - val_loss: 0.0333 - val_accuracy: 0.9900\n",
      "Epoch 7/15\n",
      " - 100s - loss: 0.0372 - accuracy: 0.9880 - val_loss: 0.0291 - val_accuracy: 0.9911\n",
      "Epoch 8/15\n",
      " - 88s - loss: 0.0386 - accuracy: 0.9880 - val_loss: 0.0299 - val_accuracy: 0.9917\n",
      "Epoch 9/15\n",
      " - 81s - loss: 0.0314 - accuracy: 0.9900 - val_loss: 0.0281 - val_accuracy: 0.9921\n",
      "Epoch 10/15\n",
      " - 95s - loss: 0.0305 - accuracy: 0.9895 - val_loss: 0.0311 - val_accuracy: 0.9917\n",
      "Epoch 11/15\n",
      " - 100s - loss: 0.0278 - accuracy: 0.9907 - val_loss: 0.0278 - val_accuracy: 0.9927\n",
      "Epoch 12/15\n",
      " - 102s - loss: 0.0272 - accuracy: 0.9915 - val_loss: 0.0298 - val_accuracy: 0.9913\n",
      "Epoch 13/15\n",
      " - 118s - loss: 0.0235 - accuracy: 0.9924 - val_loss: 0.0256 - val_accuracy: 0.9930\n",
      "Epoch 14/15\n",
      " - 97s - loss: 0.0245 - accuracy: 0.9918 - val_loss: 0.0351 - val_accuracy: 0.9907\n",
      "Epoch 15/15\n",
      " - 96s - loss: 0.0202 - accuracy: 0.9937 - val_loss: 0.0285 - val_accuracy: 0.9929\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7fe4f37a9ad0>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "triple_cnn.fit(X_train_resized, y_train,\n",
    "              batch_size=256,\n",
    "              epochs=15,\n",
    "              verbose=2,\n",
    "              validation_data=(X_test_resized, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.ndimage import shift  \n",
    "\n",
    "def shift_image(data, direction):\n",
    "    new_data = []\n",
    "    for image in data:\n",
    "        image = shift(image.reshape(28, 28), direction).flatten()\n",
    "        new_data.append(image)\n",
    "    \n",
    "    return np.array(new_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_aug = []\n",
    "for direct in ([4, 0], [-4, 0], [0, 2], [0, -2], [3, 3], [-3, 3]):\n",
    "    new_digits = shift_image(X_train, direct)\n",
    "    X_aug.extend(new_digits)\n",
    "    \n",
    "X_aug = np.vstack((X_train, np.array(X_aug)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_aug = np.array(list(y_train) * 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_aug_resized = X_aug.reshape(X_aug.shape[0], 28, 28, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(235200, 28, 28, 1)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_aug_resized.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [ EarlyStopping(patience=5), \n",
    "             ModelCheckpoint('mnist_best_model.hdf5', save_best_only=True),\n",
    "            ReduceLROnPlateau(patience=3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 235200 samples, validate on 8400 samples\n",
      "Epoch 1/15\n",
      "235200/235200 [==============================] - 617s 3ms/step - loss: 0.1977 - accuracy: 0.9354 - val_loss: 0.0333 - val_accuracy: 0.9905\n",
      "Epoch 2/15\n",
      "235200/235200 [==============================] - 577s 2ms/step - loss: 0.0508 - accuracy: 0.9841 - val_loss: 0.0303 - val_accuracy: 0.9906\n",
      "Epoch 3/15\n",
      "235200/235200 [==============================] - 580s 2ms/step - loss: 0.0361 - accuracy: 0.9887 - val_loss: 0.0244 - val_accuracy: 0.9923\n",
      "Epoch 4/15\n",
      "235200/235200 [==============================] - 567s 2ms/step - loss: 0.0295 - accuracy: 0.9909 - val_loss: 0.0226 - val_accuracy: 0.9929\n",
      "Epoch 5/15\n",
      "235200/235200 [==============================] - 536s 2ms/step - loss: 0.0259 - accuracy: 0.9918 - val_loss: 0.0221 - val_accuracy: 0.9939\n",
      "Epoch 6/15\n",
      "235200/235200 [==============================] - 496s 2ms/step - loss: 0.0224 - accuracy: 0.9929 - val_loss: 0.0194 - val_accuracy: 0.9943\n",
      "Epoch 7/15\n",
      "235200/235200 [==============================] - 503s 2ms/step - loss: 0.0201 - accuracy: 0.9936 - val_loss: 0.0210 - val_accuracy: 0.9949\n",
      "Epoch 8/15\n",
      "235200/235200 [==============================] - 500s 2ms/step - loss: 0.0176 - accuracy: 0.9943 - val_loss: 0.0203 - val_accuracy: 0.9952\n",
      "Epoch 9/15\n",
      "235200/235200 [==============================] - 554s 2ms/step - loss: 0.0158 - accuracy: 0.9949 - val_loss: 0.0210 - val_accuracy: 0.9952\n",
      "Epoch 10/15\n",
      "235200/235200 [==============================] - 557s 2ms/step - loss: 0.0087 - accuracy: 0.9973 - val_loss: 0.0200 - val_accuracy: 0.9955\n",
      "Epoch 11/15\n",
      "235200/235200 [==============================] - 557s 2ms/step - loss: 0.0070 - accuracy: 0.9976 - val_loss: 0.0203 - val_accuracy: 0.9955\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7fe5a63e9510>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doubled_cnn.fit(X_aug_resized, y_aug,\n",
    "              batch_size=256,\n",
    "              epochs=15,\n",
    "              verbose=1,\n",
    "              callbacks=callbacks,\n",
    "              validation_data=(X_test_resized, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 235200 samples, validate on 8400 samples\n",
      "Epoch 1/15\n",
      "235200/235200 [==============================] - 713s 3ms/step - loss: 0.0443 - accuracy: 0.9874 - val_loss: 0.0208 - val_accuracy: 0.9944\n",
      "Epoch 2/15\n",
      "235200/235200 [==============================] - 641s 3ms/step - loss: 0.0337 - accuracy: 0.9899 - val_loss: 0.0208 - val_accuracy: 0.9943\n",
      "Epoch 3/15\n",
      "235200/235200 [==============================] - 676s 3ms/step - loss: 0.0303 - accuracy: 0.9909 - val_loss: 0.0210 - val_accuracy: 0.9942\n",
      "Epoch 4/15\n",
      "235200/235200 [==============================] - 678s 3ms/step - loss: 0.0277 - accuracy: 0.9914 - val_loss: 0.0214 - val_accuracy: 0.9942\n",
      "Epoch 5/15\n",
      "235200/235200 [==============================] - 677s 3ms/step - loss: 0.0260 - accuracy: 0.9917 - val_loss: 0.0214 - val_accuracy: 0.9942\n",
      "Epoch 6/15\n",
      "235200/235200 [==============================] - 642s 3ms/step - loss: 0.0267 - accuracy: 0.9917 - val_loss: 0.0214 - val_accuracy: 0.9942\n",
      "Epoch 7/15\n",
      "235200/235200 [==============================] - 592s 3ms/step - loss: 0.0254 - accuracy: 0.9922 - val_loss: 0.0214 - val_accuracy: 0.9942\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7fe5a6552250>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "triple_cnn.fit(X_aug_resized, y_aug,\n",
    "              batch_size=256,\n",
    "              epochs=15,\n",
    "              verbose=1,\n",
    "              callbacks=callbacks,\n",
    "              validation_data=(X_test_resized, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8400/8400 [==============================] - 9s 1ms/step\n",
      "Loss: 0.028446206388842776, Accuracy: 0.9936904907226562\n"
     ]
    }
   ],
   "source": [
    "cnn_score = doubled_cnn.evaluate(X_test_resized, y_test)\n",
    "print('Loss: {0}, Accuracy: {1}'.format(cnn_score[0], cnn_score[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction on test part and save results in csv\n",
    "test = test.reshape(test.shape[0], 28, 28, 1)\n",
    "y_pred = doubled_cnn.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_id = np.arange(1, test.shape[0]+1)\n",
    "\n",
    "prediction = []\n",
    "for i in range(len(label_id)):\n",
    "    prediction.append(np.argmax(y_pred[i]))\n",
    "    \n",
    "submission = pd.DataFrame({'ImageId': label_id, 'Label': prediction})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('predict_digits.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
