{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D\n",
    "from keras.applications import VGG16\n",
    "from keras.utils import np_utils\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (42000, 785), test shape: (28000, 784)\n"
     ]
    }
   ],
   "source": [
    "train_data = pd.read_csv('train.csv')\n",
    "test_data = pd.read_csv('test.csv')\n",
    "\n",
    "print('Train shape: {0}, test shape: {1}'.format(train_data.shape, test_data.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels, data = train_data['label'].values, train_data.iloc[:, 1:].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(42000, 784)\n",
      "0 255\n"
     ]
    }
   ],
   "source": [
    "print(data.shape)\n",
    "print(np.min(data), np.max(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x576 with 5 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Check a few digits\n",
    "\n",
    "sample_digits = np.random.randint(0, len(data), 5)\n",
    "\n",
    "fig = plt.figure(figsize=(15, 8))\n",
    "i = 1\n",
    "for x in sample_digits:\n",
    "    ax = fig.add_subplot(1, 5, i)\n",
    "    i += 1\n",
    "    ax.set_title('True value: {0}'.format(labels[x]))\n",
    "    digit = data[x].reshape(28, 28)\n",
    "    plt.imshow(digit, cmap = plt.cm.binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale train and test data from 1 to 0\n",
    "test = test_data.values\n",
    "\n",
    "if np.max(data) > 1: data = data / 255\n",
    "if np.max(test) > 1: test = test / 255\n",
    "    \n",
    "# Convert labels to categorical\n",
    "y = np_utils.to_categorical(labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data, y, test_size=0.2, random_state=46)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build  MLP models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_inputs = X_train.shape[1]\n",
    "num_outputs = y.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_10 (Dense)             (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 10)                2570      \n",
      "=================================================================\n",
      "Total params: 535,818\n",
      "Trainable params: 535,818\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# MLP model 2 hidden layers\n",
    "first_mlp_model = Sequential([\n",
    "    Dense(512, input_dim=num_inputs, activation='relu'),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dense(num_outputs, activation='softmax')\n",
    "])\n",
    "\n",
    "first_mlp_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "first_mlp_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 33600 samples, validate on 8400 samples\n",
      "Epoch 1/12\n",
      " - 4s - loss: 0.0158 - accuracy: 0.9947 - val_loss: 0.1095 - val_accuracy: 0.9755\n",
      "Epoch 2/12\n",
      " - 4s - loss: 0.0066 - accuracy: 0.9980 - val_loss: 0.1039 - val_accuracy: 0.9764\n",
      "Epoch 3/12\n",
      " - 4s - loss: 0.0016 - accuracy: 0.9997 - val_loss: 0.1027 - val_accuracy: 0.9793\n",
      "Epoch 4/12\n",
      " - 4s - loss: 0.0022 - accuracy: 0.9994 - val_loss: 0.1065 - val_accuracy: 0.9782\n",
      "Epoch 5/12\n",
      " - 5s - loss: 0.0016 - accuracy: 0.9996 - val_loss: 0.0984 - val_accuracy: 0.9808\n",
      "Epoch 6/12\n",
      " - 5s - loss: 3.1465e-04 - accuracy: 1.0000 - val_loss: 0.1011 - val_accuracy: 0.9811\n",
      "Epoch 7/12\n",
      " - 5s - loss: 1.5549e-04 - accuracy: 1.0000 - val_loss: 0.1021 - val_accuracy: 0.9810\n",
      "Epoch 8/12\n",
      " - 5s - loss: 1.2341e-04 - accuracy: 1.0000 - val_loss: 0.1040 - val_accuracy: 0.9811\n",
      "Epoch 9/12\n",
      " - 5s - loss: 1.0491e-04 - accuracy: 1.0000 - val_loss: 0.1060 - val_accuracy: 0.9808\n",
      "Epoch 10/12\n",
      " - 5s - loss: 9.2128e-05 - accuracy: 1.0000 - val_loss: 0.1071 - val_accuracy: 0.9808\n",
      "Epoch 11/12\n",
      " - 5s - loss: 8.1379e-05 - accuracy: 1.0000 - val_loss: 0.1082 - val_accuracy: 0.9811\n",
      "Epoch 12/12\n",
      " - 5s - loss: 7.3365e-05 - accuracy: 1.0000 - val_loss: 0.1090 - val_accuracy: 0.9807\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1a94798150>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_mlp_model.fit(X_train, y_train,\n",
    "         batch_size=256,\n",
    "         epochs=12,\n",
    "         verbose=2,\n",
    "         validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MLP model 3 hidden layers and dropouts\n",
    "second_mlp_model = Sequential([\n",
    "    Dense(1024, input_dim=num_inputs, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    \n",
    "    Dense(512, activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    \n",
    "    Dense(256, activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    \n",
    "    Dense(num_outputs, activation='softmax')\n",
    "])\n",
    "\n",
    "second_mlp_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 33600 samples, validate on 8400 samples\n",
      "Epoch 1/12\n",
      " - 23s - loss: 0.4522 - accuracy: 0.8607 - val_loss: 0.1551 - val_accuracy: 0.9533\n",
      "Epoch 2/12\n",
      " - 15s - loss: 0.1743 - accuracy: 0.9460 - val_loss: 0.1116 - val_accuracy: 0.9664\n",
      "Epoch 3/12\n",
      " - 15s - loss: 0.1268 - accuracy: 0.9603 - val_loss: 0.0937 - val_accuracy: 0.9714\n",
      "Epoch 4/12\n",
      " - 15s - loss: 0.1044 - accuracy: 0.9676 - val_loss: 0.0816 - val_accuracy: 0.9758\n",
      "Epoch 5/12\n",
      " - 15s - loss: 0.0871 - accuracy: 0.9719 - val_loss: 0.0831 - val_accuracy: 0.9750\n",
      "Epoch 6/12\n",
      " - 14s - loss: 0.0745 - accuracy: 0.9754 - val_loss: 0.0823 - val_accuracy: 0.9771\n",
      "Epoch 7/12\n",
      " - 14s - loss: 0.0676 - accuracy: 0.9783 - val_loss: 0.0796 - val_accuracy: 0.9771\n",
      "Epoch 8/12\n",
      " - 14s - loss: 0.0583 - accuracy: 0.9806 - val_loss: 0.0791 - val_accuracy: 0.9769\n",
      "Epoch 9/12\n",
      " - 14s - loss: 0.0578 - accuracy: 0.9815 - val_loss: 0.0835 - val_accuracy: 0.9783\n",
      "Epoch 10/12\n",
      " - 14s - loss: 0.0497 - accuracy: 0.9835 - val_loss: 0.0777 - val_accuracy: 0.9798\n",
      "Epoch 11/12\n",
      " - 14s - loss: 0.0477 - accuracy: 0.9836 - val_loss: 0.0826 - val_accuracy: 0.9794\n",
      "Epoch 12/12\n",
      " - 14s - loss: 0.0428 - accuracy: 0.9858 - val_loss: 0.0749 - val_accuracy: 0.9811\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1a9c48ab10>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "second_mlp_model.fit(X_train, y_train,\n",
    "         batch_size=256,\n",
    "         epochs=12,\n",
    "         verbose=2,\n",
    "         validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8400/8400 [==============================] - 2s 235us/step\n",
      "Loss: 0.07485243178066975, Accuracy: 0.981071412563324\n"
     ]
    }
   ],
   "source": [
    "score = second_mlp_model.evaluate(X_test, y_test)\n",
    "print('Loss: {0}, Accuracy: {1}'.format(score[0], score[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build CNN models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resize X and y for CNN\n",
    "X_train_resized = X_train.reshape(X_train.shape[0], 28, 28, 1)\n",
    "X_test_resized = X_test.reshape(X_test.shape[0], 28, 28, 1)\n",
    "\n",
    "input_shape = X_train_resized.shape[1:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test shape: (33600, 28, 28, 1), train shape: (8400, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "print('Test shape: {0}, train shape: {1}'.format(X_train_resized.shape, X_test_resized.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_58\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_146 (Conv2D)          (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_97 (MaxPooling (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_177 (Dropout)        (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_147 (Conv2D)          (None, 11, 11, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_98 (MaxPooling (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_178 (Dropout)        (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_44 (Flatten)         (None, 1600)              0         \n",
      "_________________________________________________________________\n",
      "dense_156 (Dense)            (None, 512)               819712    \n",
      "_________________________________________________________________\n",
      "dropout_179 (Dropout)        (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_157 (Dense)            (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 843,658\n",
      "Trainable params: 843,658\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 33600 samples, validate on 8400 samples\n",
      "Epoch 1/15\n",
      " - 56s - loss: 0.4464 - accuracy: 0.8594 - val_loss: 0.1119 - val_accuracy: 0.9680\n",
      "Epoch 2/15\n",
      " - 55s - loss: 0.1260 - accuracy: 0.9613 - val_loss: 0.0717 - val_accuracy: 0.9792\n",
      "Epoch 3/15\n",
      " - 52s - loss: 0.0885 - accuracy: 0.9720 - val_loss: 0.0516 - val_accuracy: 0.9839\n",
      "Epoch 4/15\n",
      " - 48s - loss: 0.0679 - accuracy: 0.9790 - val_loss: 0.0467 - val_accuracy: 0.9864\n",
      "Epoch 5/15\n",
      " - 48s - loss: 0.0569 - accuracy: 0.9821 - val_loss: 0.0393 - val_accuracy: 0.9886\n",
      "Epoch 6/15\n",
      " - 48s - loss: 0.0505 - accuracy: 0.9836 - val_loss: 0.0393 - val_accuracy: 0.9880\n",
      "Epoch 7/15\n",
      " - 49s - loss: 0.0450 - accuracy: 0.9853 - val_loss: 0.0395 - val_accuracy: 0.9882\n",
      "Epoch 8/15\n",
      " - 50s - loss: 0.0395 - accuracy: 0.9871 - val_loss: 0.0351 - val_accuracy: 0.9910\n",
      "Epoch 9/15\n",
      " - 51s - loss: 0.0318 - accuracy: 0.9896 - val_loss: 0.0338 - val_accuracy: 0.9900\n",
      "Epoch 10/15\n",
      " - 50s - loss: 0.0312 - accuracy: 0.9899 - val_loss: 0.0329 - val_accuracy: 0.9900\n",
      "Epoch 11/15\n",
      " - 50s - loss: 0.0307 - accuracy: 0.9898 - val_loss: 0.0334 - val_accuracy: 0.9900\n",
      "Epoch 12/15\n",
      " - 49s - loss: 0.0260 - accuracy: 0.9911 - val_loss: 0.0328 - val_accuracy: 0.9907\n",
      "Epoch 13/15\n",
      " - 50s - loss: 0.0253 - accuracy: 0.9915 - val_loss: 0.0300 - val_accuracy: 0.9899\n",
      "Epoch 14/15\n",
      " - 48s - loss: 0.0240 - accuracy: 0.9923 - val_loss: 0.0302 - val_accuracy: 0.9918\n",
      "Epoch 15/15\n",
      " - 52s - loss: 0.0218 - accuracy: 0.9926 - val_loss: 0.0329 - val_accuracy: 0.9907\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1b5e5e9090>"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Two conv layers\n",
    "simple_cnn = Sequential([\n",
    "    Conv2D(32, kernel_size=(3,3), input_shape=input_shape, activation='relu'),\n",
    "    MaxPool2D(pool_size=(2,2)),\n",
    "    Dropout(0.3),\n",
    "    \n",
    "    Conv2D(64, kernel_size=(3,3), activation='relu'),\n",
    "    MaxPool2D(pool_size=(2,2)),\n",
    "    Dropout(0.3),\n",
    "    \n",
    "    Flatten(),\n",
    "    \n",
    "    Dense(512, activation='relu'),\n",
    "    Dropout(0.3),\n",
    "    \n",
    "    Dense(num_outputs, activation='softmax')\n",
    "])\n",
    "\n",
    "simple_cnn.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "simple_cnn.summary()\n",
    "\n",
    "simple_cnn.fit(X_train_resized, y_train,\n",
    "              batch_size=256,\n",
    "              epochs=15,\n",
    "              verbose=2,\n",
    "              validation_data=(X_test_resized, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_63\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_160 (Conv2D)          (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_111 (MaxPoolin (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_199 (Dropout)        (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_161 (Conv2D)          (None, 11, 11, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_112 (MaxPoolin (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_200 (Dropout)        (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_162 (Conv2D)          (None, 3, 3, 128)         73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_113 (MaxPoolin (None, 1, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_201 (Dropout)        (None, 1, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_49 (Flatten)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_169 (Dense)            (None, 1024)              132096    \n",
      "_________________________________________________________________\n",
      "dropout_202 (Dropout)        (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_170 (Dense)            (None, 10)                10250     \n",
      "=================================================================\n",
      "Total params: 235,018\n",
      "Trainable params: 235,018\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 33600 samples, validate on 8400 samples\n",
      "Epoch 1/15\n",
      " - 54s - loss: 0.8534 - accuracy: 0.7185 - val_loss: 0.1961 - val_accuracy: 0.9396\n",
      "Epoch 2/15\n",
      " - 53s - loss: 0.2571 - accuracy: 0.9217 - val_loss: 0.1220 - val_accuracy: 0.9611\n",
      "Epoch 3/15\n",
      " - 50s - loss: 0.1819 - accuracy: 0.9444 - val_loss: 0.0926 - val_accuracy: 0.9719\n",
      "Epoch 4/15\n",
      " - 50s - loss: 0.1500 - accuracy: 0.9535 - val_loss: 0.0791 - val_accuracy: 0.9740\n",
      "Epoch 5/15\n",
      " - 51s - loss: 0.1313 - accuracy: 0.9598 - val_loss: 0.0697 - val_accuracy: 0.9768\n",
      "Epoch 6/15\n",
      " - 52s - loss: 0.1118 - accuracy: 0.9646 - val_loss: 0.0629 - val_accuracy: 0.9794\n",
      "Epoch 7/15\n",
      " - 51s - loss: 0.1023 - accuracy: 0.9683 - val_loss: 0.0598 - val_accuracy: 0.9806\n",
      "Epoch 8/15\n",
      " - 51s - loss: 0.0989 - accuracy: 0.9690 - val_loss: 0.0563 - val_accuracy: 0.9823\n",
      "Epoch 9/15\n",
      " - 50s - loss: 0.0889 - accuracy: 0.9724 - val_loss: 0.0511 - val_accuracy: 0.9846\n",
      "Epoch 10/15\n",
      " - 50s - loss: 0.0816 - accuracy: 0.9737 - val_loss: 0.0517 - val_accuracy: 0.9837\n",
      "Epoch 11/15\n",
      " - 54s - loss: 0.0791 - accuracy: 0.9760 - val_loss: 0.0462 - val_accuracy: 0.9858\n",
      "Epoch 12/15\n",
      " - 53s - loss: 0.0720 - accuracy: 0.9778 - val_loss: 0.0442 - val_accuracy: 0.9864\n",
      "Epoch 13/15\n",
      " - 51s - loss: 0.0711 - accuracy: 0.9776 - val_loss: 0.0470 - val_accuracy: 0.9858\n",
      "Epoch 14/15\n",
      " - 51s - loss: 0.0680 - accuracy: 0.9783 - val_loss: 0.0486 - val_accuracy: 0.9849\n",
      "Epoch 15/15\n",
      " - 52s - loss: 0.0676 - accuracy: 0.9775 - val_loss: 0.0460 - val_accuracy: 0.9868\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1b6e423b10>"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Three conv layers\n",
    "three_conv = Sequential([\n",
    "    Conv2D(32, kernel_size=(3,3), input_shape=input_shape, activation='relu'),\n",
    "    MaxPool2D(pool_size=(2,2)),\n",
    "    Dropout(0.3),\n",
    "    \n",
    "    Conv2D(64, kernel_size=(3,3), activation='relu'),\n",
    "    MaxPool2D(pool_size=(2,2)),\n",
    "    Dropout(0.3),\n",
    "    \n",
    "    Conv2D(128, kernel_size=(3,3), activation='relu'),\n",
    "    MaxPool2D(pool_size=(2,2)),\n",
    "    Dropout(0.3),\n",
    "    \n",
    "    Flatten(),\n",
    "    \n",
    "    Dense(1024, activation='relu'),\n",
    "    Dropout(0.3),\n",
    "    \n",
    "    Dense(num_outputs, activation='softmax')\n",
    "])\n",
    "\n",
    "three_conv.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "three_conv.summary()\n",
    "\n",
    "three_conv.fit(X_train_resized, y_train,\n",
    "              batch_size=256,\n",
    "              epochs=15,\n",
    "              verbose=2,\n",
    "              validation_data=(X_test_resized, y_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_83\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_243 (Conv2D)          (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "conv2d_244 (Conv2D)          (None, 24, 24, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_150 (MaxPoolin (None, 12, 12, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_264 (Dropout)        (None, 12, 12, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_245 (Conv2D)          (None, 12, 12, 64)        18496     \n",
      "_________________________________________________________________\n",
      "conv2d_246 (Conv2D)          (None, 10, 10, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_151 (MaxPoolin (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_265 (Dropout)        (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_69 (Flatten)         (None, 1600)              0         \n",
      "_________________________________________________________________\n",
      "dense_215 (Dense)            (None, 1024)              1639424   \n",
      "_________________________________________________________________\n",
      "dropout_266 (Dropout)        (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_216 (Dense)            (None, 10)                10250     \n",
      "=================================================================\n",
      "Total params: 1,714,666\n",
      "Trainable params: 1,714,666\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 33600 samples, validate on 8400 samples\n",
      "Epoch 1/20\n",
      " - 107s - loss: 0.4115 - accuracy: 0.8674 - val_loss: 0.0844 - val_accuracy: 0.9739\n",
      "Epoch 2/20\n",
      " - 87s - loss: 0.0902 - accuracy: 0.9711 - val_loss: 0.0475 - val_accuracy: 0.9862\n",
      "Epoch 3/20\n",
      " - 94s - loss: 0.0641 - accuracy: 0.9796 - val_loss: 0.0419 - val_accuracy: 0.9879\n",
      "Epoch 4/20\n",
      " - 85s - loss: 0.0532 - accuracy: 0.9830 - val_loss: 0.0345 - val_accuracy: 0.9895\n",
      "Epoch 5/20\n",
      " - 90s - loss: 0.0439 - accuracy: 0.9864 - val_loss: 0.0352 - val_accuracy: 0.9885\n",
      "Epoch 6/20\n",
      " - 86s - loss: 0.0371 - accuracy: 0.9880 - val_loss: 0.0297 - val_accuracy: 0.9913\n",
      "Epoch 7/20\n",
      " - 86s - loss: 0.0329 - accuracy: 0.9895 - val_loss: 0.0300 - val_accuracy: 0.9905\n",
      "Epoch 8/20\n",
      " - 85s - loss: 0.0300 - accuracy: 0.9912 - val_loss: 0.0283 - val_accuracy: 0.9920\n",
      "Epoch 9/20\n",
      " - 87s - loss: 0.0268 - accuracy: 0.9917 - val_loss: 0.0278 - val_accuracy: 0.9924\n",
      "Epoch 10/20\n",
      " - 85s - loss: 0.0224 - accuracy: 0.9924 - val_loss: 0.0321 - val_accuracy: 0.9919\n",
      "Epoch 11/20\n",
      " - 87s - loss: 0.0221 - accuracy: 0.9928 - val_loss: 0.0316 - val_accuracy: 0.9915\n",
      "Epoch 12/20\n",
      " - 86s - loss: 0.0205 - accuracy: 0.9932 - val_loss: 0.0316 - val_accuracy: 0.9908\n",
      "Epoch 13/20\n",
      " - 123s - loss: 0.0180 - accuracy: 0.9940 - val_loss: 0.0363 - val_accuracy: 0.9901\n",
      "Epoch 14/20\n",
      " - 129s - loss: 0.0174 - accuracy: 0.9937 - val_loss: 0.0369 - val_accuracy: 0.9911\n",
      "Epoch 15/20\n",
      " - 100s - loss: 0.0175 - accuracy: 0.9943 - val_loss: 0.0314 - val_accuracy: 0.9914\n",
      "Epoch 16/20\n",
      " - 101s - loss: 0.0159 - accuracy: 0.9948 - val_loss: 0.0284 - val_accuracy: 0.9918\n",
      "Epoch 17/20\n",
      " - 92s - loss: 0.0128 - accuracy: 0.9955 - val_loss: 0.0347 - val_accuracy: 0.9911\n",
      "Epoch 18/20\n",
      " - 90s - loss: 0.0148 - accuracy: 0.9948 - val_loss: 0.0295 - val_accuracy: 0.9926\n",
      "Epoch 19/20\n",
      " - 85s - loss: 0.0125 - accuracy: 0.9957 - val_loss: 0.0299 - val_accuracy: 0.9918\n",
      "Epoch 20/20\n",
      " - 87s - loss: 0.0141 - accuracy: 0.9954 - val_loss: 0.0284 - val_accuracy: 0.9937\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1ba2e7d850>"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Two double conv layers\n",
    "doubled_cnn = Sequential([\n",
    "    Conv2D(32, kernel_size=(3,3), input_shape=input_shape, activation='relu'),\n",
    "    Conv2D(32, kernel_size=(3,3), activation='relu'),\n",
    "    MaxPool2D(pool_size=(2,2)),\n",
    "    Dropout(0.5),\n",
    "    \n",
    "    Conv2D(64, kernel_size=(3,3), padding='same', activation='relu'),\n",
    "    Conv2D(64, kernel_size=(3,3), activation='relu'),\n",
    "    MaxPool2D(pool_size=(2,2)),\n",
    "    Dropout(0.3),\n",
    "    \n",
    "    Flatten(),\n",
    "    \n",
    "    Dense(1024, activation='relu'),\n",
    "    Dropout(0.3),\n",
    "    \n",
    "    Dense(num_outputs, activation='softmax')\n",
    "])\n",
    "\n",
    "doubled_cnn.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "doubled_cnn.summary()\n",
    "\n",
    "doubled_cnn.fit(X_train_resized, y_train,\n",
    "              batch_size=256,\n",
    "              epochs=20,\n",
    "              verbose=2,\n",
    "              validation_data=(X_test_resized, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_92\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_298 (Conv2D)          (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "conv2d_299 (Conv2D)          (None, 24, 24, 32)        9248      \n",
      "_________________________________________________________________\n",
      "conv2d_300 (Conv2D)          (None, 22, 22, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_169 (MaxPoolin (None, 11, 11, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_293 (Dropout)        (None, 11, 11, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_301 (Conv2D)          (None, 11, 11, 64)        18496     \n",
      "_________________________________________________________________\n",
      "conv2d_302 (Conv2D)          (None, 9, 9, 64)          36928     \n",
      "_________________________________________________________________\n",
      "conv2d_303 (Conv2D)          (None, 7, 7, 64)          36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_170 (MaxPoolin (None, 3, 3, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_294 (Dropout)        (None, 3, 3, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_78 (Flatten)         (None, 576)               0         \n",
      "_________________________________________________________________\n",
      "dense_234 (Dense)            (None, 1024)              590848    \n",
      "_________________________________________________________________\n",
      "dropout_295 (Dropout)        (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_235 (Dense)            (None, 10)                10250     \n",
      "=================================================================\n",
      "Total params: 712,266\n",
      "Trainable params: 712,266\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 33600 samples, validate on 8400 samples\n",
      "Epoch 1/15\n",
      " - 99s - loss: 0.6898 - accuracy: 0.7711 - val_loss: 0.1394 - val_accuracy: 0.9565\n",
      "Epoch 2/15\n",
      " - 91s - loss: 0.1527 - accuracy: 0.9526 - val_loss: 0.0783 - val_accuracy: 0.9761\n",
      "Epoch 3/15\n",
      " - 92s - loss: 0.0963 - accuracy: 0.9704 - val_loss: 0.0550 - val_accuracy: 0.9835\n",
      "Epoch 4/15\n",
      " - 90s - loss: 0.0754 - accuracy: 0.9769 - val_loss: 0.0454 - val_accuracy: 0.9869\n",
      "Epoch 5/15\n",
      " - 90s - loss: 0.0682 - accuracy: 0.9786 - val_loss: 0.0475 - val_accuracy: 0.9856\n",
      "Epoch 6/15\n",
      " - 90s - loss: 0.0568 - accuracy: 0.9815 - val_loss: 0.0401 - val_accuracy: 0.9875\n",
      "Epoch 7/15\n",
      " - 90s - loss: 0.0485 - accuracy: 0.9845 - val_loss: 0.0364 - val_accuracy: 0.9887\n",
      "Epoch 8/15\n",
      " - 91s - loss: 0.0425 - accuracy: 0.9860 - val_loss: 0.0320 - val_accuracy: 0.9906\n",
      "Epoch 9/15\n",
      " - 90s - loss: 0.0387 - accuracy: 0.9875 - val_loss: 0.0328 - val_accuracy: 0.9906\n",
      "Epoch 10/15\n",
      " - 90s - loss: 0.0333 - accuracy: 0.9890 - val_loss: 0.0347 - val_accuracy: 0.9896\n",
      "Epoch 11/15\n",
      " - 91s - loss: 0.0337 - accuracy: 0.9892 - val_loss: 0.0295 - val_accuracy: 0.9906\n",
      "Epoch 12/15\n",
      " - 91s - loss: 0.0305 - accuracy: 0.9899 - val_loss: 0.0306 - val_accuracy: 0.9910\n",
      "Epoch 13/15\n",
      " - 91s - loss: 0.0276 - accuracy: 0.9909 - val_loss: 0.0290 - val_accuracy: 0.9912\n",
      "Epoch 14/15\n",
      " - 94s - loss: 0.0268 - accuracy: 0.9910 - val_loss: 0.0278 - val_accuracy: 0.9919\n",
      "Epoch 15/15\n",
      " - 91s - loss: 0.0297 - accuracy: 0.9900 - val_loss: 0.0287 - val_accuracy: 0.9919\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1bb5430e50>"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Two triple conv layers\n",
    "triple_cnn = Sequential([\n",
    "    \n",
    "    Conv2D(32, kernel_size=(3,3), input_shape=input_shape, activation='relu'),\n",
    "    Conv2D(32, kernel_size=(3,3), activation='relu'),\n",
    "    Conv2D(32, kernel_size=(3,3), activation='relu'),\n",
    "    MaxPool2D(pool_size=(2,2)),\n",
    "    Dropout(0.5),\n",
    "    \n",
    "    Conv2D(64, kernel_size=(3,3), padding='same', activation='relu'),\n",
    "    Conv2D(64, kernel_size=(3,3), activation='relu'),\n",
    "    Conv2D(64, kernel_size=(3,3), activation='relu'),\n",
    "    MaxPool2D(pool_size=(2,2)),\n",
    "    Dropout(0.3),\n",
    "    \n",
    "    Flatten(),\n",
    "    \n",
    "    Dense(1024, activation='relu'),\n",
    "    Dropout(0.3),\n",
    "    \n",
    "    Dense(num_outputs, activation='softmax')\n",
    "])\n",
    "\n",
    "triple_cnn.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "triple_cnn.summary()\n",
    "\n",
    "triple_cnn.fit(X_train_resized, y_train,\n",
    "              batch_size=512,\n",
    "              epochs=15,\n",
    "              verbose=2,\n",
    "              validation_data=(X_test_resized, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8400/8400 [==============================] - 9s 1ms/step\n",
      "Loss: 0.028446206388842776, Accuracy: 0.9936904907226562\n"
     ]
    }
   ],
   "source": [
    "cnn_score = doubled_cnn.evaluate(X_test_resized, y_test)\n",
    "print('Loss: {0}, Accuracy: {1}'.format(cnn_score[0], cnn_score[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction on test part and save results in csv\n",
    "test = test.reshape(test.shape[0], 28, 28, 1)\n",
    "y_pred = doubled_cnn.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_id = np.arange(1, test.shape[0]+1)\n",
    "\n",
    "prediction = []\n",
    "for i in range(len(label_id)):\n",
    "    prediction.append(np.argmax(y_pred[i]))\n",
    "    \n",
    "submission = pd.DataFrame({'ImageId': label_id, 'Label': prediction})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('predict_digits.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
